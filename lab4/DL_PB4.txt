Q1:
    -Backpropagation:
    z(x) = W¹x + b¹     b=bias
    h(x) = g(z(x))

    -SGD 
        w² = w¹ - n(dL/dz)

    1:
        CNN: 4,4,3,3
        w = 0.1
        b = 0.1
        Loss = Square Error
        SCG:
            w¹=[4x4],w²≃[3x4] outputsXinputs
            z¹=[0.3,0.3,0.3,0.3] g(z¹)=[0.2913,0.2913,0.2913,0.2913]
            z²=[0.2165,0.2165,0.2165,0.2165] g(z²) = [0.2132,0.2132,0.2132,0.2132]
            z³=[0.16396,0.16396,0.16396,0.16396]

            L(y;ŷ) = 0.5*SUM((ŷ-y)²)6
            dL/dz =ŷ-y

    2:
        w<-w-n(1(b))SUM[i-1 toB](...)

Q2:

    1:
        cross entropy
            L(ŷ,y) = -SUM(Ylog(nk))
            dL/dz=-y+n
            
